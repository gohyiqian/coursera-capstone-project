{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Solving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/DSX-Python35\n\n  added / updated specs: \n    - folium=0.5.0\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2019.3.9   |       hecc5488_0         146 KB  conda-forge\n    altair-2.2.2               |           py35_1         462 KB  conda-forge\n    openssl-1.0.2r             |       h14c3975_0         3.1 MB  conda-forge\n    branca-0.3.1               |             py_0          25 KB  conda-forge\n    certifi-2018.8.24          |        py35_1001         139 KB  conda-forge\n    folium-0.5.0               |             py_0          45 KB  conda-forge\n    vincent-0.4.4              |             py_1          28 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         4.0 MB\n\nThe following NEW packages will be INSTALLED:\n\n    altair:          2.2.2-py35_1      conda-forge\n    branca:          0.3.1-py_0        conda-forge\n    folium:          0.5.0-py_0        conda-forge\n    vincent:         0.4.4-py_1        conda-forge\n\nThe following packages will be UPDATED:\n\n    ca-certificates: 2019.1.23-0                   --> 2019.3.9-hecc5488_0 conda-forge\n    certifi:         2018.8.24-py35_1              --> 2018.8.24-py35_1001 conda-forge\n    openssl:         1.0.2p-h14c3975_0             --> 1.0.2r-h14c3975_0   conda-forge\n\n\nDownloading and Extracting Packages\nca-certificates-2019 | 146 KB    | ##################################### | 100% \naltair-2.2.2         | 462 KB    | ##################################### | 100% \nopenssl-1.0.2r       | 3.1 MB    | ##################################### | 100% \nbranca-0.3.1         | 25 KB     | ##################################### | 100% \ncertifi-2018.8.24    | 139 KB    | ##################################### | 100% \nfolium-0.5.0         | 45 KB     | ##################################### | 100% \nvincent-0.4.4        | 28 KB     | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nLibraries imported.\n"
                }
            ], 
            "source": "import numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n\nprint('Libraries imported.')"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "BeautifulSoap imported\n1:\"Postcode\"\n2:\"Borough\"\n3:\"Neighbourhood\n\"\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/ipykernel/__main__.py:74: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
                }, 
                {
                    "execution_count": 3, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postcode</th>\n      <th>Borough</th>\n      <th>Neighbourhood</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>M3A</td>\n      <td>North York</td>\n      <td>Parkwoods</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M4A</td>\n      <td>North York</td>\n      <td>Victoria Village</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M5A</td>\n      <td>Downtown Toronto</td>\n      <td>Harbourfront</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>M5A</td>\n      <td>Downtown Toronto</td>\n      <td>Regent Park</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>M6A</td>\n      <td>North York</td>\n      <td>Lawrence Heights</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>M6A</td>\n      <td>North York</td>\n      <td>Lawrence Manor</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>M7A</td>\n      <td>Queen's Park</td>\n      <td>Not assigned</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>M9A</td>\n      <td>Etobicoke</td>\n      <td>Islington Avenue</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>M1B</td>\n      <td>Scarborough</td>\n      <td>Rouge</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>M1B</td>\n      <td>Scarborough</td>\n      <td>Malvern</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>M3B</td>\n      <td>North York</td>\n      <td>Don Mills North</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>M4B</td>\n      <td>East York</td>\n      <td>Woodbine Gardens</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   Postcode           Borough   Neighbourhood\\n\n2       M3A        North York         Parkwoods\n3       M4A        North York  Victoria Village\n4       M5A  Downtown Toronto      Harbourfront\n5       M5A  Downtown Toronto       Regent Park\n6       M6A        North York  Lawrence Heights\n7       M6A        North York    Lawrence Manor\n8       M7A      Queen's Park      Not assigned\n10      M9A         Etobicoke  Islington Avenue\n11      M1B       Scarborough             Rouge\n12      M1B       Scarborough           Malvern\n14      M3B        North York   Don Mills North\n15      M4B         East York  Woodbine Gardens"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import requests # import & load  necessary libraries and packages\nimport lxml.html as lh\nimport pandas as pd\nurl='https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'  # wikipedia URL tnat has the Toronto Postcodes and details\nfrom bs4 import BeautifulSoup  # import Beautifulsoup # Get BeautifulSoup package\nprint('BeautifulSoap imported')\n\n# Using BS to scrap the wikipedia HTML and generate a csv file with the postal codes etc\nimport requests  # import requests library\n\nwebsite_URL=requests.get('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M').text\n\nToronto_soup = BeautifulSoup(website_URL,\"lxml\")  # Align it to Toronto\n\nMy_table = Toronto_soup.find(\"table\",{\"class\":\"wikitable sortable\"}) # obtain wikitable sortable\n\n#Create a handle, page, to handle the contents of the website\npage = requests.get(url)\n\n#Store the contents of the website under doc\ndoc = lh.fromstring(page.content)\n\n#Parse data that are stored between <tr>..</tr> of HTML\ntr_elements = doc.xpath('//tr')\n\n#Check the length of the first 12 rows\n[len(T) for T in tr_elements[:12]]\ntr_elements = doc.xpath('//tr')\n\n#Create empty list\nDict=[]\ncol=[]\ni=0\n\n#For each row, store each first element (header) and an empty list\nfor t in tr_elements[0]:\n    i+=1\n    name=t.text_content()\n    print ('%d:\"%s\"'%(i,name))\n    col.append((name,[]))\n    \n#Since out first row is the header, data is stored on the second row onwards\nfor j in range(1,len(tr_elements)):\n    #T is our j'th row\n    T=tr_elements[j]\n    \n    #If row is not of size 3, the //tr data is not from our table \n    if len(T)!=3:\n        break\n    \n    #i is the index of our column\n    i=0\n    \n    #Iterate through each element of the row\n    for t in T.iterchildren():\n        data=t.text_content() \n        #Check if row is empty\n        if i>0:\n        #Convert any numerical value to integers\n            try:\n                data=int(data)\n            except:\n                pass\n        #Append the data to the empty list of the i'th column\n        col[i][1].append(data)\n        #Increment i for the next column\n        i+=1    \n[len(C) for (title,C) in col]\nDict={title:column for (title,column) in col}  # Dictionary with Postcodes, Borough and Neighbourhoods\n\ndf=pd.DataFrame(Dict)  # Creating the pandas Dataframe using the dictionary values\ndf_Borough=df[df.Borough != 'Not assigned']   # get rid of \"Not assigned\" boroughs\ndf_Borough.reset_index(drop=True)\ndf_Borough['Neighbourhood\\n'] = df_Borough['Neighbourhood\\n'].replace({r'\\n': ''}, regex=True)  # get rid of the eol marker from the neighbourhood values\ndf_Borough = df_Borough[['Postcode','Borough','Neighbourhood\\n']]\ndf_Borough.head(12)"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 4, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(211, 3)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "df_Borough.shape"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}